{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T00:25:05.664597Z","iopub.execute_input":"2023-10-02T00:25:05.664887Z","iopub.status.idle":"2023-10-02T00:25:05.671182Z","shell.execute_reply.started":"2023-10-02T00:25:05.664865Z","shell.execute_reply":"2023-10-02T00:25:05.670540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\ntest = pd.read_csv(\"/kaggle/input/playground-series-s3e22/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s3e22/train.csv\")\ntrain = train.drop([\"id\",\"hospital_number\"],axis=1)\nprint(train.head())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.672214Z","iopub.execute_input":"2023-10-02T00:25:05.672427Z","iopub.status.idle":"2023-10-02T00:25:05.706212Z","shell.execute_reply.started":"2023-10-02T00:25:05.672407Z","shell.execute_reply":"2023-10-02T00:25:05.705526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_contingency(column):\n    contingency = pd.crosstab(train[column],train[\"outcome\"])\n    return contingency","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.708029Z","iopub.execute_input":"2023-10-02T00:25:05.708479Z","iopub.status.idle":"2023-10-02T00:25:05.712841Z","shell.execute_reply.started":"2023-10-02T00:25:05.708460Z","shell.execute_reply":"2023-10-02T00:25:05.711771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(make_contingency(\"pain\"))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.722728Z","iopub.execute_input":"2023-10-02T00:25:05.723025Z","iopub.status.idle":"2023-10-02T00:25:05.737039Z","shell.execute_reply.started":"2023-10-02T00:25:05.723003Z","shell.execute_reply":"2023-10-02T00:25:05.735841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\nabcd={}\ncramer = {}\nfor i in train.columns:\n    arr= make_contingency(i)\n#     arr= make_contingency(i).drop(\"euthanized\",axis=1)\n    arr+=.1\n    chi2, p, dof, expected = chi2_contingency(arr)\n    n = train.shape[0]\n    k = arr.shape[1]\n    r = arr.shape[0]\n    \n    cramerV= np.sqrt(chi2 / (n * min(k - 1, r - 1)))\n    cramer[i]=cramerV\n\n    abcd[i] = p\nfinal = dict(sorted(abcd.items(), key=lambda x:x[1]))\nCramerFinal = dict(sorted(cramer.items(), key=lambda x:x[1],reverse=True))\n\nprint(final)\nprint(\"\\n\" + str(CramerFinal))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.744073Z","iopub.execute_input":"2023-10-02T00:25:05.744675Z","iopub.status.idle":"2023-10-02T00:25:05.900201Z","shell.execute_reply.started":"2023-10-02T00:25:05.744634Z","shell.execute_reply":"2023-10-02T00:25:05.899447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poss_col = []\nposs_col2=[]\nfor i in list(final.keys()):\n    if final[i]<=.05:\n        poss_col.append(i)\nfor i in list(CramerFinal.keys()):\n    if CramerFinal[i]>.4:\n        poss_col2.append(i)\nprint(poss_col)\nprint(poss_col2)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.902388Z","iopub.execute_input":"2023-10-02T00:25:05.903401Z","iopub.status.idle":"2023-10-02T00:25:05.909820Z","shell.execute_reply.started":"2023-10-02T00:25:05.903351Z","shell.execute_reply":"2023-10-02T00:25:05.907967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train1 = train.drop([\"lesion_3\"],axis=1)\ntrain1 = train\nfor i in train1.columns:\n    if type(train1[i][0])==type(\"hello\"):\n        unique = list(train1[i].unique())\n        for a in unique:\n            train1[i]=train1[i].replace(a,unique.index(a)+1)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.911919Z","iopub.execute_input":"2023-10-02T00:25:05.912175Z","iopub.status.idle":"2023-10-02T00:25:05.957222Z","shell.execute_reply.started":"2023-10-02T00:25:05.912154Z","shell.execute_reply":"2023-10-02T00:25:05.956033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_column(column):\n    min_val = column.min()\n    max_val = column.max()\n    return (column - min_val) / (max_val - min_val)\ntrain1 = train1.apply(normalize_column)\nprint(train1.head())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.958955Z","iopub.execute_input":"2023-10-02T00:25:05.959203Z","iopub.status.idle":"2023-10-02T00:25:05.987068Z","shell.execute_reply.started":"2023-10-02T00:25:05.959184Z","shell.execute_reply":"2023-10-02T00:25:05.986090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"datalist = (train1[poss_col2].values.tolist())\nx_train = np.array([x[1:] for x in datalist])\n\ny_train=np.zeros((len(x_train),3))\nfor i in range(len(datalist)):\n    y_train[i][int(datalist[i][0]*2)]=1\nx_train = x_train[:,np.newaxis,:]\nprint(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:05.988239Z","iopub.execute_input":"2023-10-02T00:25:05.988503Z","iopub.status.idle":"2023-10-02T00:25:05.999397Z","shell.execute_reply.started":"2023-10-02T00:25:05.988477Z","shell.execute_reply":"2023-10-02T00:25:05.997716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.000992Z","iopub.execute_input":"2023-10-02T00:25:06.001351Z","iopub.status.idle":"2023-10-02T00:25:06.016237Z","shell.execute_reply.started":"2023-10-02T00:25:06.001319Z","shell.execute_reply":"2023-10-02T00:25:06.014965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sig(x):\n  return 1/(1+np.exp(-x))\ndef sigDerv(x):\n  return sig(x)*(1-sig(x))\ndef relu(x):\n    return np.maximum(0,x)\ndef reluDerv(x):\n    return np.where(x>0,1,0)\n\ndef cost(actual,predicted):\n  return np.average((actual-predicted)**2)\ndef costDerv(actual,predicted):\n  return 2*(predicted-actual)/predicted.size\nclass NeuralNetwork:\n  def __init__(self):\n    self.layers = []\n\n  def add(self,layer):\n    self.layers.append(layer)\n\n  def train(self, input, actualOutput, trials):\n\n    trialNumber = 0\n    for x in range(trials): #Goes through each trial of practice\n      success = 0\n      total = 0\n      for y in range(len(input)):\n        output = input[y] #Technically first input (it's the data of the drawing)\n        for z in self.layers: #Forward propagation\n          output = z.forward(output) #Goes through the layers, getting an successful (?) prediction\n        error = costDerv(actualOutput[y],output)\n        if (actualOutput[y].argmax()==output.argmax()): #Success counter\n          success+=1\n        total+=1\n        for z in reversed(self.layers): #Backward propagation\n          error = z.backward(error)\n      trialNumber+=1\n      if(total==0):\n        print(\"Invalid, division by zero| Successes \" + str(success))\n      else:\n        print(\"Trial: \"+ str(trialNumber)+\"|\"+ str(success) + \"/\" + str(total) + \"|Percentage:\" +str(round(success/total,3))) #Success calculator\n  def test(self, input, actualOutput, trials):\n    trialNumber = 0\n    for x in range(trials): #Goes through each trial of practice\n      success = 0\n      total = 0\n      for y in range(len(input)):\n        output = input[y] #Technically first input (it's the data of the drawing)\n        for z in self.layers: #Forward propagation\n          output = z.forward(output) #Goes through the layers, getting an successful (?) prediction\n        if (actualOutput[y].argmax()==output.argmax()): #Success counter\n          success+=1\n        total+=1\n      trialNumber+=1\n      if(total==0):\n        print(\"Invalid, division by zero| Successes \" + str(success))\n      else:\n        print(\"Trial: \"+ str(trialNumber)+\"|\"+ str(success) + \"/\" + str(total) + \"|Percentage:\" +str(round(success/total,3))) #Success calculator\n  def get_csv(self,data):\n    \n    results=[]\n    for i in range(len(data)):\n        output = data[i] #Technically first input (it's the data of the drawing)\n        for z in self.layers: #Forward propagation\n          output = z.forward(output) #Goes through the layers, getting an successful (?) prediction\n        results.append(output[0].argmax())\n    return results\n\nclass layer:\n  def __init__(self,inputSize,outputSize): #i is input size, o is output size\n    self.weights = np.random.rand(inputSize, outputSize) #Creates a i by o array of weights, the (0,2) represent connectetions between 3rd top neuron and next top neuron, etc\n    self.bias = np.random.rand(1,outputSize) #Creates a 1 by o array of random biases [0,0.23,0.64,...]\n  def forward(self,inputData):\n    self.input = inputData\n    self.output = sig(np.dot(self.input, self.weights) +self.bias) #self.output is an o by 1 array of outputs, activated by sig function\n    return self.output\n  def backward(self,outputError): #Output error is the gradient descent recursively given\n    inputError = np.dot(outputError,self.weights.T)\n    weightError = np.dot(self.input.T,outputError)\n    self.weights -= weightError*.1\n    self.bias -= outputError*.1\n    return inputError*sigDerv(self.input) #returns the gradient descent deactivated of sig by chain rule\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.018230Z","iopub.execute_input":"2023-10-02T00:25:06.018554Z","iopub.status.idle":"2023-10-02T00:25:06.034215Z","shell.execute_reply.started":"2023-10-02T00:25:06.018530Z","shell.execute_reply":"2023-10-02T00:25:06.033181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = NeuralNetwork()\nnet.add(layer(len(poss_col2)-1,64))\nnet.add(layer(64,3))\nfor a in range(30):\n  randomX = np.random.randint(0,1135)\n  print(\"Training \" + str(a))\n  net.train(x_train[randomX:randomX+100], y_train[randomX:randomX+100],1) #Testing the output\n#   net.train(x_train, y_train,35) #training the network\n\n# print(\"Network is now trained\")\nfor a in range(100):\n  randomX = np.random.randint(0,1135)\n  print(\"Test \" + str(a))\n  net.test(x_train[randomX:randomX+100], y_train[randomX:randomX+100],1) #Testing the output ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.035571Z","iopub.execute_input":"2023-10-02T00:25:06.036042Z","iopub.status.idle":"2023-10-02T00:25:06.378454Z","shell.execute_reply.started":"2023-10-02T00:25:06.036016Z","shell.execute_reply":"2023-10-02T00:25:06.377423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(net.get_csv(x_train))\nop=[]\nfor i in y_train:\n    op.append(i.argmax())\nprint(op)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.379559Z","iopub.execute_input":"2023-10-02T00:25:06.379827Z","iopub.status.idle":"2023-10-02T00:25:06.406244Z","shell.execute_reply.started":"2023-10-02T00:25:06.379808Z","shell.execute_reply":"2023-10-02T00:25:06.405401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test1.columns:\n    if type(test1[i][0])==type(\"hello\"):\n        unique = list(test1[i].unique())\n        for a in unique:\n            test1[i]=test1[i].replace(a,unique.index(a)+1)\ntest1 = test1.apply(normalize_column)\nnewTest = test1[poss_col2[1:]]\n\n\ndatalist = (newTest.values.tolist())\nx_test = np.array([x for x in datalist])\nx_test = x_test[:,np.newaxis,:]\nANSWER = net.get_csv(x_test)\n\nprint(ANSWER)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.408186Z","iopub.execute_input":"2023-10-02T00:25:06.408413Z","iopub.status.idle":"2023-10-02T00:25:06.441971Z","shell.execute_reply.started":"2023-10-02T00:25:06.408394Z","shell.execute_reply":"2023-10-02T00:25:06.441162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nwith open('/kaggle/working/HenryWang.csv', \"w\") as file:\n    writer = csv.writer(file)\n    writer.writerow([\"id\",\"outcome\"])\n    for row in range(len(ANSWER)):\n        if ANSWER[row]==2:\n            outcome=\"lived\"\n        elif ANSWER[row]==1:\n            outcome=\"euthanized\"\n        else:\n            outcome=\"died\"\n        writer.writerow([test[\"id\"][row],outcome])\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T00:25:06.443167Z","iopub.execute_input":"2023-10-02T00:25:06.443612Z","iopub.status.idle":"2023-10-02T00:25:06.454417Z","shell.execute_reply.started":"2023-10-02T00:25:06.443570Z","shell.execute_reply":"2023-10-02T00:25:06.453031Z"},"trusted":true},"execution_count":null,"outputs":[]}]}